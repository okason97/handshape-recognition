{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "!pip install -q tf-nightly-gpu-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20190522\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, ZeroPadding2D, Dense, Dropout, Activation, Convolution2D, Reshape\n",
    "from tensorflow.keras.layers import AveragePooling2D, GlobalAveragePooling2D, MaxPooling2D, BatchNormalization\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras import initializers\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import handshape_datasets as hd\n",
    "\n",
    "DATASET_NAME = \"lsa16\"\n",
    "\n",
    "data = hd.load(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = data[0]\n",
    "labels = data[1]['y']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features,\n",
    "                                                    labels,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).shuffle(10000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(Model):\n",
    "    def __init__(self, nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, \n",
    "                 dropout_rate=0.0, weight_decay=1e-4, classes=1000, batch_size=32, with_se_layers=True):\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        self.eps = 1.1e-5\n",
    "        \n",
    "        self.with_se_layers = with_se_layers\n",
    "                \n",
    "        # compute compression factor\n",
    "        compression = 1.0 - reduction\n",
    "        \n",
    "        self.concat_axis = 3\n",
    "\n",
    "        # From architecture for ImageNet (Table 1 in the paper)\n",
    "        nb_filter = 64\n",
    "        nb_layers = [6,12,24,16] # For DenseNet-121\n",
    "\n",
    "        self.initial_layers = []\n",
    "        self.initial_layers.append(ZeroPadding2D((3, 3), name='conv1_zeropadding', \n",
    "                                   input_shape=(32, 32, 3), batch_size=batch_size))\n",
    "        self.initial_layers.append(Convolution2D(nb_filter, 7, 2, name='conv1', use_bias=False))\n",
    "        self.initial_layers.append(BatchNormalization(epsilon=self.eps, axis=self.concat_axis, name='conv1_bn'))\n",
    "        self.initial_layers.append(Activation('relu', name='relu1'))\n",
    "        self.initial_layers.append(ZeroPadding2D((1, 1), name='pool1_zeropadding'))\n",
    "        self.initial_layers.append(MaxPooling2D((3, 3), strides=(2, 2), name='pool1'))\n",
    "        \n",
    "        self.dense_blocks = []\n",
    "        self.transition_blocks = []\n",
    "        self.se_dense_blocks = []  \n",
    "        self.se_transition_blocks = []\n",
    "        \n",
    "        # Add dense blocks\n",
    "        for block_idx in range(nb_dense_block - 1):\n",
    "            stage = block_idx+2\n",
    "            block, nb_filter = self.dense_block(stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "            self.dense_blocks.append(block)\n",
    "        \n",
    "            if (with_se_layers):\n",
    "                self.se_dense_blocks.append(self.se_block(stage, 'dense', nb_filter))\n",
    "                        \n",
    "            # Add transition_block\n",
    "            self.transition_blocks.append(self.transition_block(stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay))\n",
    "            nb_filter = int(nb_filter * compression)\n",
    "            \n",
    "            if (with_se_layers):\n",
    "                self.se_transition_blocks.append(self.se_block(stage, 'transition', nb_filter))\n",
    "\n",
    "        final_stage = stage + 1\n",
    "        block, nb_filter = self.dense_block(final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
    "        self.dense_blocks.append(block)\n",
    "\n",
    "        if (with_se_layers):\n",
    "            self.se_dense_blocks.append(self.se_block(final_stage, 'dense', nb_filter))\n",
    "        \n",
    "        self.final_layers = self.final_block(nb_filter, classes)       \n",
    "    \n",
    "    def final_block(self, nb_filter, classes):\n",
    "        block = []\n",
    "        block.append(BatchNormalization(epsilon=self.eps, axis=self.concat_axis, name='conv_final_blk_bn'))\n",
    "        block.append(Activation('relu', name='relu_final_blk'))\n",
    "        block.append(GlobalAveragePooling2D(name='pool_final'))\n",
    "        block.append(Dense(classes, name='fc6'))\n",
    "        block.append(Activation('softmax', name='prob'))\n",
    "        return block\n",
    "    \n",
    "    def conv_block(self, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
    "        conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
    "        relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
    "\n",
    "        # 1x1 Convolution (Bottleneck layer)\n",
    "        inter_channel = nb_filter * 4  \n",
    "        block = []\n",
    "        block.append(BatchNormalization(epsilon=self.eps, axis=self.concat_axis, name=conv_name_base+'_x1_bn'))\n",
    "        block.append(Activation('relu', name=relu_name_base+'_x1'))\n",
    "        block.append(Convolution2D(inter_channel, 1, 1, name=conv_name_base+'_x1', use_bias=False))\n",
    "\n",
    "        if dropout_rate:\n",
    "            block.append(Dropout(dropout_rate))\n",
    "\n",
    "        # 3x3 Convolution\n",
    "        block.append(BatchNormalization(epsilon=self.eps, axis=self.concat_axis, name=conv_name_base+'_x2_bn'))\n",
    "        block.append(Activation('relu', name=relu_name_base+'_x2'))\n",
    "        block.append(ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding'))\n",
    "        block.append(Convolution2D(nb_filter, 3, 1, name=conv_name_base+'_x2', use_bias=False))\n",
    "\n",
    "        if dropout_rate:\n",
    "            block.append(Dropout(dropout_rate))\n",
    "        return block\n",
    "                                        \n",
    "    def se_block(self, stage, previous, nb_filter, ratio = 16):\n",
    "        se_name = 'se' + str(stage) + '_' + previous\n",
    "        block = []\n",
    "        block.append(GlobalAveragePooling2D(name='global_average_pooling_2d_'+se_name))\n",
    "        block.append(Dense(nb_filter // ratio, name='dense_relu_'+se_name))\n",
    "        block.append(Activation('relu', name='relu_'+se_name))\n",
    "        block.append(Dense(nb_filter, name='dense_sigmoid_'+se_name))\n",
    "        block.append(Activation('sigmoid', name='sigmoid_'+se_name))\n",
    "        return block\n",
    "        \n",
    "\n",
    "    def dense_block(self, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, \n",
    "                    grow_nb_filters=True):\n",
    "        block = []\n",
    "        for i in range(nb_layers):\n",
    "            branch = i+1\n",
    "            block.append(self.conv_block(stage, branch, growth_rate, dropout_rate, weight_decay))\n",
    "\n",
    "            if grow_nb_filters:\n",
    "                nb_filter += growth_rate\n",
    "\n",
    "        return block, nb_filter\n",
    "                                        \n",
    "    def transition_block(self, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
    "        conv_name_base = 'conv' + str(stage) + '_blk'\n",
    "        relu_name_base = 'relu' + str(stage) + '_blk'\n",
    "        pool_name_base = 'pool' + str(stage) \n",
    "\n",
    "        block = []\n",
    "        block.append(BatchNormalization(epsilon=self.eps, axis=self.concat_axis, name=conv_name_base+'_bn'))\n",
    "        block.append(Activation('relu', name=relu_name_base))\n",
    "        block.append(Convolution2D(int(nb_filter * compression), 1, 1, name=conv_name_base, use_bias=False))\n",
    "\n",
    "        if dropout_rate:\n",
    "            block.append(Dropout(dropout_rate))\n",
    "\n",
    "        block.append(AveragePooling2D((2, 2), strides=(2, 2), name=pool_name_base))\n",
    "\n",
    "        return block\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.initial_layers:\n",
    "            x = layer(x)\n",
    "        i = 0\n",
    "        for transition_block in self.transition_blocks:\n",
    "            concat_feat = x\n",
    "            for conv_block in self.dense_blocks[i]:                                    \n",
    "                for layer in conv_block:                                    \n",
    "                    x = layer(x)\n",
    "                x = tf.concat([concat_feat, x], self.concat_axis)\n",
    "                concat_feat = x\n",
    "            if (self.with_se_layers):\n",
    "                init = x\n",
    "                for layer in self.se_dense_blocks[i]:\n",
    "                    x = layer(x)\n",
    "                x = tf.expand_dims(x,1)\n",
    "                x = init * tf.expand_dims(x,1) \n",
    "            for layer in transition_block:                                    \n",
    "                x = layer(x)\n",
    "            if (self.with_se_layers):\n",
    "                init = x\n",
    "                for layer in self.se_transition_blocks[i]:\n",
    "                    x = layer(x)\n",
    "                x = tf.expand_dims(x,1)\n",
    "                x = init * tf.expand_dims(x,1) \n",
    "            i += 1\n",
    "        concat_feat = x\n",
    "        for conv_block in self.dense_blocks[i]:                                    \n",
    "            for layer in conv_block:                                    \n",
    "                x = layer(x)\n",
    "            x = tf.concat([concat_feat, x], self.concat_axis)\n",
    "            concat_feat = x\n",
    "        if (self.with_se_layers):\n",
    "            init = x\n",
    "            for layer in self.se_dense_blocks[i]:\n",
    "                x = layer(x)\n",
    "            x = tf.expand_dims(x,1)\n",
    "            x = init * tf.expand_dims(x,1) \n",
    "        for layer in self.final_layers:\n",
    "            x = layer(x)                                      \n",
    "        return x\n",
    "\n",
    "model = DenseNet(classes=16)\n",
    "# model.load_weights(weights_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(tf.cast(images, tf.float32))\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "    predictions = model(tf.cast(images, tf.float32))\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.774296283721924, Accuracy: 5.7835822105407715, Test Loss: 2.774871349334717, Test Accuracy: 4.545454502105713\n",
      "Saved model to disk\n",
      "Epoch 11, Loss: 2.7915639877319336, Accuracy: 7.157394886016846, Test Loss: 3.1303629875183105, Test Accuracy: 5.165289402008057\n",
      "Epoch 21, Loss: 2.7821226119995117, Accuracy: 7.276119232177734, Test Loss: 2.972669839859009, Test Accuracy: 4.59956693649292\n",
      "Epoch 31, Loss: 2.780043601989746, Accuracy: 7.384448528289795, Test Loss: 2.916815757751465, Test Accuracy: 4.337732315063477\n",
      "Epoch 41, Loss: 2.641867160797119, Accuracy: 11.730978965759277, Test Loss: 2.7376818656921387, Test Accuracy: 9.28492259979248\n",
      "Epoch 51, Loss: 2.2340028285980225, Accuracy: 24.85001564025879, Test Loss: 2.372903823852539, Test Accuracy: 21.130422592163086\n",
      "Epoch 61, Loss: 1.9273940324783325, Accuracy: 34.93699264526367, Test Loss: 2.110305070877075, Test Accuracy: 30.14778709411621\n",
      "Epoch 71, Loss: 1.6770542860031128, Accuracy: 43.33876419067383, Test Loss: 1.9135130643844604, Test Accuracy: 37.505332946777344\n",
      "Epoch 81, Loss: 1.4833886623382568, Accuracy: 49.82264709472656, Test Loss: 1.7736896276474, Test Accuracy: 43.04620361328125\n",
      "Epoch 91, Loss: 1.3354367017745972, Accuracy: 54.778987884521484, Test Loss: 1.655591607093811, Test Accuracy: 47.53996276855469\n",
      "Epoch 101, Loss: 1.2077902555465698, Accuracy: 59.09930419921875, Test Loss: 1.5563626289367676, Test Accuracy: 51.47389602661133\n",
      "Saved model to disk\n",
      "Epoch 111, Loss: 1.0990182161331177, Accuracy: 62.78404998779297, Test Loss: 1.4890100955963135, Test Accuracy: 54.903770446777344\n",
      "Epoch 121, Loss: 1.008196473121643, Accuracy: 65.85975646972656, Test Loss: 1.4421132802963257, Test Accuracy: 57.74480056762695\n",
      "Epoch 131, Loss: 0.9312354326248169, Accuracy: 68.46587371826172, Test Loss: 1.4138641357421875, Test Accuracy: 60.1607666015625\n",
      "Epoch 141, Loss: 0.8651903867721558, Accuracy: 70.70233917236328, Test Loss: 1.4005377292633057, Test Accuracy: 62.250160217285156\n",
      "Epoch 151, Loss: 0.8078929781913757, Accuracy: 72.64258575439453, Test Loss: 1.3959614038467407, Test Accuracy: 64.02769470214844\n",
      "Epoch 161, Loss: 0.7577133178710938, Accuracy: 74.341796875, Test Loss: 1.395994782447815, Test Accuracy: 65.5797119140625\n",
      "Epoch 171, Loss: 0.7134025692939758, Accuracy: 75.84227752685547, Test Loss: 1.3985607624053955, Test Accuracy: 66.95020294189453\n",
      "Epoch 181, Loss: 0.6739881038665771, Accuracy: 77.17695617675781, Test Loss: 1.4027307033538818, Test Accuracy: 68.15251922607422\n",
      "Epoch 191, Loss: 0.6387007236480713, Accuracy: 78.37187957763672, Test Loss: 1.4079886674880981, Test Accuracy: 69.23091888427734\n",
      "Epoch 201, Loss: 0.6069245934486389, Accuracy: 79.44790649414062, Test Loss: 1.4139286279678345, Test Accuracy: 70.2152099609375\n",
      "Saved model to disk\n",
      "Epoch 211, Loss: 0.5781604051589966, Accuracy: 80.42194366455078, Test Loss: 1.4203680753707886, Test Accuracy: 71.106201171875\n",
      "Epoch 221, Loss: 0.5519992709159851, Accuracy: 81.30783081054688, Test Loss: 1.427178144454956, Test Accuracy: 71.9045639038086\n",
      "Epoch 231, Loss: 0.528103232383728, Accuracy: 82.11701202392578, Test Loss: 1.4342107772827148, Test Accuracy: 72.6288833618164\n",
      "Epoch 241, Loss: 0.5061902403831482, Accuracy: 82.85904693603516, Test Loss: 1.4413886070251465, Test Accuracy: 73.29309844970703\n",
      "Epoch 251, Loss: 0.48602327704429626, Accuracy: 83.54195404052734, Test Loss: 1.4486418962478638, Test Accuracy: 73.90438079833984\n",
      "Epoch 261, Loss: 0.4674016833305359, Accuracy: 84.17253112792969, Test Loss: 1.4558868408203125, Test Accuracy: 74.46446990966797\n",
      "Epoch 271, Loss: 0.4501543939113617, Accuracy: 84.75656127929688, Test Loss: 1.4630863666534424, Test Accuracy: 74.97344207763672\n",
      "Epoch 281, Loss: 0.43413466215133667, Accuracy: 85.29904174804688, Test Loss: 1.4702229499816895, Test Accuracy: 75.4461898803711\n",
      "Epoch 291, Loss: 0.41921594738960266, Accuracy: 85.8042221069336, Test Loss: 1.4772511720657349, Test Accuracy: 75.88644409179688\n",
      "Epoch 301, Loss: 0.4052885174751282, Accuracy: 86.27584838867188, Test Loss: 1.484198808670044, Test Accuracy: 76.29744720458984\n",
      "Saved model to disk\n",
      "Epoch 311, Loss: 0.3922567367553711, Accuracy: 86.7171401977539, Test Loss: 1.4910904169082642, Test Accuracy: 76.68201446533203\n",
      "Epoch 321, Loss: 0.3800368905067444, Accuracy: 87.13093566894531, Test Loss: 1.4978902339935303, Test Accuracy: 77.04261779785156\n",
      "Epoch 331, Loss: 0.3685554265975952, Accuracy: 87.51972961425781, Test Loss: 1.504586100578308, Test Accuracy: 77.3814468383789\n",
      "Epoch 341, Loss: 0.357747346162796, Accuracy: 87.8857192993164, Test Loss: 1.5112136602401733, Test Accuracy: 77.70038604736328\n",
      "Epoch 351, Loss: 0.34755510091781616, Accuracy: 88.2308578491211, Test Loss: 1.5176509618759155, Test Accuracy: 78.00116729736328\n",
      "Epoch 361, Loss: 0.33792755007743835, Accuracy: 88.55686950683594, Test Loss: 1.5238468647003174, Test Accuracy: 78.2852783203125\n",
      "Epoch 371, Loss: 0.3288189768791199, Accuracy: 88.86531066894531, Test Loss: 1.5298352241516113, Test Accuracy: 78.55406951904297\n",
      "Epoch 381, Loss: 0.3201885521411896, Accuracy: 89.15755462646484, Test Loss: 1.5356937646865845, Test Accuracy: 78.80875396728516\n",
      "Epoch 391, Loss: 0.3119995892047882, Accuracy: 89.43485260009766, Test Loss: 1.541451334953308, Test Accuracy: 79.0504150390625\n",
      "Epoch 401, Loss: 0.3042190670967102, Accuracy: 89.69832611083984, Test Loss: 1.5470894575119019, Test Accuracy: 79.28002166748047\n",
      "Saved model to disk\n",
      "Epoch 411, Loss: 0.2968171238899231, Accuracy: 89.948974609375, Test Loss: 1.5526326894760132, Test Accuracy: 79.49845123291016\n",
      "Epoch 421, Loss: 0.2897668480873108, Accuracy: 90.18771362304688, Test Loss: 1.5581239461898804, Test Accuracy: 79.70650482177734\n",
      "Epoch 431, Loss: 0.2830437123775482, Accuracy: 90.4153823852539, Test Loss: 1.5634207725524902, Test Accuracy: 79.9049072265625\n",
      "Epoch 441, Loss: 0.27662548422813416, Accuracy: 90.63272094726562, Test Loss: 1.5684713125228882, Test Accuracy: 80.09430694580078\n",
      "Epoch 451, Loss: 0.27049189805984497, Accuracy: 90.84042358398438, Test Loss: 1.573306918144226, Test Accuracy: 80.27531433105469\n",
      "Epoch 461, Loss: 0.26462438702583313, Accuracy: 91.03910827636719, Test Loss: 1.5779778957366943, Test Accuracy: 80.4484634399414\n",
      "Epoch 471, Loss: 0.2590060234069824, Accuracy: 91.22936248779297, Test Loss: 1.5824568271636963, Test Accuracy: 80.61426544189453\n",
      "Epoch 481, Loss: 0.25362128019332886, Accuracy: 91.41170501708984, Test Loss: 1.5867866277694702, Test Accuracy: 80.76529693603516\n",
      "Epoch 491, Loss: 0.24845589697360992, Accuracy: 91.58661651611328, Test Loss: 1.5910131931304932, Test Accuracy: 80.91017150878906\n",
      "Epoch 501, Loss: 0.24349668622016907, Accuracy: 91.75454711914062, Test Loss: 1.595117449760437, Test Accuracy: 81.04926300048828\n",
      "Saved model to disk\n",
      "Epoch 511, Loss: 0.23873159289360046, Accuracy: 91.91590881347656, Test Loss: 1.5990875959396362, Test Accuracy: 81.18291473388672\n",
      "Epoch 521, Loss: 0.23414941132068634, Accuracy: 92.07107543945312, Test Loss: 1.6029319763183594, Test Accuracy: 81.30780029296875\n",
      "Epoch 531, Loss: 0.22973981499671936, Accuracy: 92.22039794921875, Test Loss: 1.606633186340332, Test Accuracy: 81.42941284179688\n",
      "Epoch 541, Loss: 0.22549323737621307, Accuracy: 92.36419677734375, Test Loss: 1.610221028327942, Test Accuracy: 81.54862213134766\n",
      "Epoch 551, Loss: 0.22140079736709595, Accuracy: 92.50277709960938, Test Loss: 1.6137264966964722, Test Accuracy: 81.66350555419922\n",
      "Epoch 561, Loss: 0.21745426952838898, Accuracy: 92.63642120361328, Test Loss: 1.6172071695327759, Test Accuracy: 81.7742919921875\n",
      "Epoch 571, Loss: 0.21364596486091614, Accuracy: 92.765380859375, Test Loss: 1.6206859350204468, Test Accuracy: 81.8812026977539\n",
      "Epoch 581, Loss: 0.20996874570846558, Accuracy: 92.88990020751953, Test Loss: 1.6241397857666016, Test Accuracy: 81.98442840576172\n",
      "Epoch 591, Loss: 0.20641598105430603, Accuracy: 93.01020812988281, Test Loss: 1.6275221109390259, Test Accuracy: 82.08416748046875\n",
      "Epoch 601, Loss: 0.20298144221305847, Accuracy: 93.12650299072266, Test Loss: 1.6309205293655396, Test Accuracy: 82.18058013916016\n",
      "Saved model to disk\n",
      "Epoch 611, Loss: 0.1996593177318573, Accuracy: 93.23900604248047, Test Loss: 1.634462833404541, Test Accuracy: 82.27384185791016\n",
      "Epoch 621, Loss: 0.19644419848918915, Accuracy: 93.34786987304688, Test Loss: 1.6381844282150269, Test Accuracy: 82.36409759521484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 631, Loss: 0.19333097338676453, Accuracy: 93.45329284667969, Test Loss: 1.642032265663147, Test Accuracy: 82.44609069824219\n",
      "Epoch 641, Loss: 0.1903148889541626, Accuracy: 93.55542755126953, Test Loss: 1.6460139751434326, Test Accuracy: 82.52494049072266\n",
      "Epoch 651, Loss: 0.187391459941864, Accuracy: 93.65442657470703, Test Loss: 1.6501444578170776, Test Accuracy: 82.60135650634766\n",
      "Epoch 661, Loss: 0.1845564991235733, Accuracy: 93.75041961669922, Test Loss: 1.6545281410217285, Test Accuracy: 82.67546844482422\n",
      "Epoch 671, Loss: 0.1818060278892517, Accuracy: 93.84355926513672, Test Loss: 1.6592994928359985, Test Accuracy: 82.74736785888672\n",
      "Epoch 681, Loss: 0.17913633584976196, Accuracy: 93.9339599609375, Test Loss: 1.6646921634674072, Test Accuracy: 82.8171615600586\n",
      "Epoch 691, Loss: 0.17658229172229767, Accuracy: 94.021484375, Test Loss: 1.7164568901062012, Test Accuracy: 82.80379486083984\n",
      "Epoch 701, Loss: 0.18612699210643768, Accuracy: 93.80362701416016, Test Loss: 1.7022984027862549, Test Accuracy: 82.69733428955078\n",
      "Saved model to disk\n",
      "Epoch 711, Loss: 0.18570686876773834, Accuracy: 93.81783294677734, Test Loss: 1.6855107545852661, Test Accuracy: 82.75582885742188\n",
      "Epoch 721, Loss: 0.18359331786632538, Accuracy: 93.88778686523438, Test Loss: 1.6694729328155518, Test Accuracy: 82.83265686035156\n",
      "Epoch 731, Loss: 0.18143922090530396, Accuracy: 93.96119689941406, Test Loss: 1.6542255878448486, Test Accuracy: 82.92293548583984\n",
      "Epoch 741, Loss: 0.1790481060743332, Accuracy: 94.04093170166016, Test Loss: 1.639369010925293, Test Accuracy: 83.02253723144531\n",
      "Epoch 751, Loss: 0.17666621506214142, Accuracy: 94.12027740478516, Test Loss: 1.625622034072876, Test Accuracy: 83.13006591796875\n",
      "Epoch 761, Loss: 0.17434485256671906, Accuracy: 94.19754028320312, Test Loss: 1.6131771802902222, Test Accuracy: 83.2382583618164\n",
      "Epoch 771, Loss: 0.1720835566520691, Accuracy: 94.27279663085938, Test Loss: 1.6020045280456543, Test Accuracy: 83.34561920166016\n",
      "Epoch 781, Loss: 0.16988018155097961, Accuracy: 94.34613037109375, Test Loss: 1.591816782951355, Test Accuracy: 83.46234893798828\n",
      "Epoch 791, Loss: 0.16773252189159393, Accuracy: 94.41761016845703, Test Loss: 1.5823783874511719, Test Accuracy: 83.58043670654297\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 800\n",
    "    \n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(test_images, test_labels)\n",
    "\n",
    "    if (epoch % 10 == 0):\n",
    "        template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "        print (template.format(epoch+1,\n",
    "                               train_loss.result(),\n",
    "                               train_accuracy.result()*100,\n",
    "                               test_loss.result(),\n",
    "                               test_accuracy.result()*100))\n",
    "    \n",
    "    if (epoch % 100 == 0):\n",
    "        # serialize weights to HDF5\n",
    "        model.save_weights(\"dropout_se_model_epoch{}.h5\".format(epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
